{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import random, math, torch, numpy as np, matplotlib.pyplot as plt\n",
    "from tinyai.model import *\n",
    "from tinyai.learner import *\n",
    "from tinyai.hooks import *\n",
    "from tinyai.init import *\n",
    "import fastcore.all as fc\n",
    "from functools import partial\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "def get_tokens(input_file):\n",
    "    with open(input_file) as f:\n",
    "        text = f.read()\n",
    "    tokens = enc.encode(text)\n",
    "    return tokens\n",
    "\n",
    "cwd = os.getcwd()\n",
    "input_file = f\"{cwd}/fast-nanogpt/input.txt\"\n",
    "tokens = get_tokens(input_file)[:20000]\n",
    "train, valid = tokens[:int(len(tokens)*0.8)], tokens[int(len(tokens)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 512]), torch.Size([4, 512]), 31, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = DataSet(torch.tensor(train), T=512)\n",
    "# vds = DataSet(torch.tensor(valid))\n",
    "dls = DataLoaders.from_dd([tds, None], batch_size=4)\n",
    "# dls = DataLoaders.from_dd([tds, vds], batch_size=4)\n",
    "x, y = next(iter(dls.train))\n",
    "x.shape, y.shape, len(tds), len(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ActivationStats(fc.risinstance(Block))\n",
    "cbs = [TrainCB(), InitWeightsCB(), DeviceCB(), MetricsCB(), ProgressCB()]\n",
    "def fit(model, epochs=1, xtra_cbs=None):\n",
    "    lrn = Learner(model, dls=dls, opt_func=optim.AdamW, cbs=cbs + fc.L(xtra_cbs), lr=3e-4)\n",
    "    lrn.fit(epochs, valid=False)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'tinyai.init.ResidualLinear'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResidualLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mGPT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPTConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/playground/notebooks/fast-nanogpt/tinyai/init.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "??get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "\n",
    "class TimeCallback(Callback):\n",
    "    def before_batch(self, learn):\n",
    "        self.t0 = time.time()\n",
    "\n",
    "    def _log(self, d):\n",
    "        pass\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.time()\n",
    "        dt = (t1 - self.t0) * 1000\n",
    "        x, _ = learn.batch\n",
    "        tokens_per_sec = x.shape[0] * x.shape[1] / (t1 - self.t0)\n",
    "\n",
    "        print(\n",
    "            f\"step {learn.iter}, loss: {learn.loss.item():.2f}, time: {dt:.2f}msi, tok/sec: {tokens_per_sec:.0f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9.016</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 10.95, time: 1276.20msi, tok/sec: 1605\n",
      "step 1, loss: 9.47, time: 500.31msi, tok/sec: 4093\n",
      "step 2, loss: 9.20, time: 513.62msi, tok/sec: 3987\n",
      "step 3, loss: 8.89, time: 499.57msi, tok/sec: 4100\n",
      "step 4, loss: 8.75, time: 509.90msi, tok/sec: 4017\n",
      "step 5, loss: 8.46, time: 499.94msi, tok/sec: 4096\n",
      "step 6, loss: 8.13, time: 503.26msi, tok/sec: 4069\n",
      "step 7, loss: 8.04, time: 387.94msi, tok/sec: 3959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tinyai.learner.Learner at 0x7f32214ce650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(1337)\n",
    "model = get_model()\n",
    "fit(model, xtra_cbs=[TimeCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: what are dtypes\n",
    "![](https://devblogs.nvidia.com/wp-content/uploads/2020/05/TensorFloat32-TF32.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TensorFloat32\n",
    "# Only available for Ampere GPUs\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9.020</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 11.01, time: 554.20msi, tok/sec: 3695\n",
      "step 1, loss: 9.41, time: 502.87msi, tok/sec: 4073\n",
      "step 2, loss: 9.24, time: 516.27msi, tok/sec: 3967\n",
      "step 3, loss: 8.77, time: 497.99msi, tok/sec: 4113\n",
      "step 4, loss: 8.70, time: 511.42msi, tok/sec: 4005\n",
      "step 5, loss: 8.52, time: 505.68msi, tok/sec: 4050\n",
      "step 6, loss: 8.21, time: 509.02msi, tok/sec: 4023\n",
      "step 7, loss: 8.05, time: 388.18msi, tok/sec: 3957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tinyai.learner.Learner at 0x7f3131762ef0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "fit(model, xtra_cbs=[TimeCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable [auto mixed precision](https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html#adding-torch-autocast)\n",
    "\n",
    "Lower Precision could speed up training and inference time. \n",
    "**Precision support matrix**\n",
    "\n",
    "|             | Ampere                                       | Turing                 | Volta                  |\n",
    "|-------------|----------------------------------------------|------------------------|------------------------|\n",
    "| Tensor Core | FP64, TF32, bfloat16, FP16, INT8, INT4, INT1 | FP16, INT8, INT4, INT1 | FP16                   |\n",
    "| CUDAÂ® Core  | FP64, FP32, FP16, bfloat16, INT8             | FP64, FP32, FP16, INT8 | FP64, FP32, FP16, INT8 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "torch_dtype_float16 = (\n",
    "    torch.bfloat16\n",
    "    if torch.cuda.is_bf16_supported()\n",
    "    else torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MixedPrecisionTrainCB(TrainCB):\n",
    "\n",
    "    def predict(self, learn):\n",
    "        with torch.autocast(device_type=default_device, enabled=learn.training, dtype=torch_dtype_float16):\n",
    "            learn.preds, learn.loss = learn.model(*learn.batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_bf16_supported()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [MixedPrecisionTrainCB(), InitWeightsCB(), DeviceCB(), MetricsCB(), ProgressCB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9.247</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 10.93, time: 274.46msi, tok/sec: 7462\n",
      "step 1, loss: 9.53, time: 215.97msi, tok/sec: 9483\n",
      "step 2, loss: 9.31, time: 207.25msi, tok/sec: 9882\n",
      "step 3, loss: 8.97, time: 206.69msi, tok/sec: 9908\n",
      "step 4, loss: 8.97, time: 209.05msi, tok/sec: 9797\n",
      "step 5, loss: 8.85, time: 210.77msi, tok/sec: 9717\n",
      "step 6, loss: 8.63, time: 211.34msi, tok/sec: 9691\n",
      "step 7, loss: 8.62, time: 169.57msi, tok/sec: 9058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tinyai.learner.Learner at 0x7f31313ac2b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, xtra_cbs=[TimeCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: compile\n",
    "1. gelu example\n",
    "2. why compile? explain hbm to sm round trip\n",
    "3. trouble shooting, no speed up for old cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9.300</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 10.98, time: 20778.76msi, tok/sec: 99\n",
      "step 1, loss: 9.48, time: 204.07msi, tok/sec: 10036\n",
      "step 2, loss: 9.37, time: 176.18msi, tok/sec: 11625\n",
      "step 3, loss: 9.02, time: 174.25msi, tok/sec: 11754\n",
      "step 4, loss: 9.06, time: 174.96msi, tok/sec: 11706\n",
      "step 5, loss: 8.94, time: 176.01msi, tok/sec: 11636\n",
      "step 6, loss: 8.73, time: 175.16msi, tok/sec: 11692\n",
      "step 7, loss: 8.66, time: 18980.65msi, tok/sec: 81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tinyai.learner.Learner at 0x7f311b7c0550>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, xtra_cbs=[TimeCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile primarily helps with memory bandwidth bound workloads by reducing data round trips between HBM and SM, in which case SM is so fast that it keeps waiting for data to arrive from HBM. Older cards may not see much speed up because they are slow on computation.\n",
    "\n",
    "See https://huggingface.co/docs/transformers/perf_torch_compile for compile speed up benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CompileCB(Callback):\n",
    "    def before_fit(self, learn):\n",
    "        learn.model = torch.compile(learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "If you are seeing warning like `/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda`, it indicates may that the linker is trying to use a version of libcuda.so that is not compatible with the CUDA version you are using.\n",
    "\n",
    "For example if you are using CUDA 12.0, ensure that libcuda.so if from CUDA 12.0.\n",
    "1. Update the LD_LIBRARY_PATH\n",
    "```sh\n",
    "export LD_LIBRARY_PATH=/usr/local/cuda-12.0/targets/x86_64-linux/lib/stubs:$LD_LIBRARY_PATH\n",
    "```\n",
    "\n",
    "2. Update the symbolic link\n",
    "```sh\n",
    "sudo ln -sf /usr/local/cuda-12.0/targets/x86_64-linux/lib/stubs/libcuda.so /usr/lib/libcuda.so\n",
    "sudo ln -sf /usr/local/cuda-12.0/targets/x86_64-linux/lib/stubs/libcuda.so /usr/lib64/libcuda.so\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flash attention\n",
    "\n",
    "Flash attention is more memory efficient, it never materializes the full attention matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FastCausalSelfAttention(CausalSelfAttention):\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        # nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\n",
    "        # e.g. in GPT-2 (124M), n_head=12, hs=64, so nh*hs=C=768 channels in the Transformer\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, T, C) -> (B, T, nh, hs) -> (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        # attention (materializes the large (T,T) matrix for all the queries and keys)\n",
    "        # att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        # att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "        # att = F.softmax(att, dim=-1)\n",
    "        # y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(GPTConfig(), proj=ResidualLinear, attn=FastCausalSelfAttention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9.254</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 10.79, time: 14325.45msi, tok/sec: 143\n",
      "step 1, loss: 9.44, time: 173.57msi, tok/sec: 11799\n",
      "step 2, loss: 9.80, time: 158.02msi, tok/sec: 12960\n",
      "step 3, loss: 8.95, time: 158.00msi, tok/sec: 12962\n",
      "step 4, loss: 8.85, time: 158.39msi, tok/sec: 12930\n",
      "step 5, loss: 8.79, time: 158.87msi, tok/sec: 12891\n",
      "step 6, loss: 8.63, time: 158.42msi, tok/sec: 12928\n",
      "step 7, loss: 8.60, time: 14632.54msi, tok/sec: 105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tinyai.learner.Learner at 0x7f3166775ed0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, xtra_cbs=[CompileCB(), TimeCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use kernel friendly numbers\n",
    "\n",
    "A lot of cuda kernels are written in terms of power of 2, and if the input is not a power of 2, it will spin up a kernel that is a power of 2, and then do some extra work to handle the rest.\n",
    "\n",
    "So look up the nn code, if a number is power of 2, it is nice number. Otherwise it is a ugly number, and see if you can make increase it to the nearest power of 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mGPTConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mblock_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50257\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_layer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_head\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_embd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      GPTConfig(block_size: int = 1024, vocab_size: int = 50257, n_layer: int = 12, n_head: int = 12, n_embd: int = 768)\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mGPTConfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mblock_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;31m# max sequence length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50257\u001b[0m \u001b[0;31m# number of tokens: 50,000 BPE merges + 256 bytes tokens + 1 <|endoftext|> token\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_layer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;31m# number of layers\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_head\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;31m# number of heads\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_embd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m768\u001b[0m \u001b[0;31m# embedding dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/playground/notebooks/fast-nanogpt/tinyai/model.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "??GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_model():\n",
    "    return GPT(GPTConfig(vocab_size=50304), proj=ResidualLinear, attn=FastCausalSelfAttention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50304, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): FastCausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (c_proj): ResidualLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='tanh')\n",
       "          (c_proj): ResidualLinear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9.126</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 10.95, time: 14317.53msi, tok/sec: 143\n",
      "step 1, loss: 9.40, time: 186.72msi, tok/sec: 10968\n",
      "step 2, loss: 9.05, time: 142.46msi, tok/sec: 14376\n",
      "step 3, loss: 8.84, time: 142.22msi, tok/sec: 14400\n",
      "step 4, loss: 8.85, time: 140.66msi, tok/sec: 14560\n",
      "step 5, loss: 8.70, time: 140.10msi, tok/sec: 14618\n",
      "step 6, loss: 8.52, time: 139.23msi, tok/sec: 14710\n",
      "step 7, loss: 8.57, time: 14279.15msi, tok/sec: 108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tinyai.learner.Learner at 0x7f3166843e50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, xtra_cbs=[CompileCB(), TimeCallback()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

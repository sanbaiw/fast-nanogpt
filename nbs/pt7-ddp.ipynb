{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import random, math, torch, numpy as np, matplotlib.pyplot as plt\n",
    "from tinyai.model import *\n",
    "from tinyai.learner import *\n",
    "from tinyai.hooks import *\n",
    "from tinyai.init import *\n",
    "from tinyai.speedup import *\n",
    "from tinyai.hyperparam import *\n",
    "import fastcore.all as fc\n",
    "from functools import partial\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "ddp_enabled = dist.is_available() and int(os.environ.get(\"RANK\", -1)) != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddp_enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ddp_enabled:\n",
    "    init_process_group(backend=\"nccl\")\n",
    "    ddp_rank = dist.get_rank()\n",
    "    ddp_local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    ddp_world_size = dist.get_world_size()\n",
    "    device = f\"cuda:{ddp_local_rank}\"\n",
    "    torch.cuda.set_device(device)\n",
    "    master_process = ddp_rank == 0\n",
    "else:\n",
    "    ddp_rank = 0\n",
    "    ddp_local_rank = 0\n",
    "    ddp_world_size = 1\n",
    "    master_process = True\n",
    "    device = default_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1337)\n",
    "torch.cuda.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_dir = f\"{cwd}/fast-nanogpt\"\n",
    "pattern = \"input.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_tensor(f):\n",
    "    def _f(*args, **kwargs):\n",
    "        return torch.tensor(f(*args, **kwargs), dtype=torch.long)\n",
    "    return _f\n",
    "\n",
    "@to_tensor\n",
    "def get_tokens(input_file):\n",
    "    with open(input_file) as f:\n",
    "        text = f.read()\n",
    "    tokens = enc.encode(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([338025])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = get_tokens(f\"{data_dir}/{pattern}\")\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterable dataset\n",
    "\n",
    "In distributed settings, we have multiple process that access the same dataset. So we need to make sure that each process only access its own pard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class FSDataSet(IterableDataset):\n",
    "    \"\"\" A dataset that loads data from a directory of files.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, data_dir, pattern=None, token_fn=get_tokens, T=32, num_proc=1, rank=0\n",
    "    ):\n",
    "        self.T = T\n",
    "        self.num_proc = num_proc\n",
    "        self.rank = rank\n",
    "        self.pattern = pattern\n",
    "        self.token_fn = token_fn\n",
    "\n",
    "        self.shards = self.get_shards(data_dir, pattern)\n",
    "        self.current_shard = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_shard = 0\n",
    "        # each process starts at a different offset corresponding to its rank\n",
    "        self.current_pos = self.T * self.rank\n",
    "        self.tokens = self.token_fn(self.shards[self.current_shard])\n",
    "\n",
    "    def get_shards(self, data_dir, pattern=None):\n",
    "        shards = os.listdir(data_dir)\n",
    "        if pattern is not None:\n",
    "            shards = [os.path.join(data_dir, s) for s in shards if pattern in s]\n",
    "        shards = sorted(shards)\n",
    "        return shards\n",
    "\n",
    "    def step(self):\n",
    "        # advance position\n",
    "        self.current_pos += self.T * self.num_proc\n",
    "        # if next step will go over the end of the shard, move to the next shard\n",
    "        if self.current_pos + self.T * self.num_proc + 1 > len(self.tokens):\n",
    "            self.current_shard = (self.current_shard + 1) % len(self.shards)\n",
    "            self.tokens = self.token_fn(self.shards[self.current_shard])\n",
    "            self.current_pos = self.T * self.rank\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        buf = self.tokens[self.current_pos : self.current_pos + self.T + 1]\n",
    "        x = buf[:-1]\n",
    "        y = buf[1:]\n",
    "\n",
    "        self.step()\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = FSDataSet(\n",
    "    data_dir,\n",
    "    pattern=pattern,\n",
    "    T=32,\n",
    "    num_proc=ddp_world_size,\n",
    "    rank=ddp_rank,\n",
    ")\n",
    "it = iter(tds)\n",
    "x, y = next(it)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dd([tds, None], batch_size=4, drop_last=True)\n",
    "x, y = next(iter(dls.train))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FixedStepCallback(Callback):\n",
    "    def __init__(self, step_count=50):\n",
    "        self.step_count = step_count\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        if hasattr(learn, \"opt\"):\n",
    "            if learn.opt._step_count >= self.step_count:\n",
    "                raise CancelFitException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_accu_steps = 50\n",
    "cbs = [GradAccuTrainCB(grad_accu_steps), InitWeightsCB(), DeviceCB()]\n",
    "def fit(model, epochs=1, opt_func=optim.AdamW, xtra_cbs=None, lr=3e-4):\n",
    "    lrn = Learner(model, dls=dls, opt_func=opt_func, cbs=cbs + fc.L(xtra_cbs), lr=lr)\n",
    "    lrn.fit(epochs, valid=False)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1337)\n",
    "model = get_model().to(default_device)\n",
    "record = GradAccuRecordCB(lr=get_lr, grad_norm=get_grad_norm)\n",
    "schd = GradAccuScheduleCB(partial(CosineLR, warmup_steps=10, max_steps=50))\n",
    "fit(model, opt_func=get_optimizer, xtra_cbs=[schd, record, GradAccuLogCallback(), FixedStepCallback(8)], lr=6e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.recs['grad_norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDP\n",
    "\n",
    "DDP container handles the communication between the different processes. The forward pass remains unchained, after backward is called it uses `all_reduce` to synchronize across all GPUs to average the gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ddp_enabled:\n",
    "    model = DDP(model, device_ids=[ddp_local_rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DDPCB(Callback):\n",
    "    def __init__(self, local_rank, compile=True):\n",
    "        self.compile = compile\n",
    "        self.local_rank = local_rank\n",
    "\n",
    "    def before_fit(self, learn):\n",
    "        if self.compile:\n",
    "            learn.model = torch.compile(learn.model)\n",
    "\n",
    "        learn.model = DDP(learn.model, device_ids=[self.local_rank])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using gradient accumulation, we don't want to synchronize the gradients after each batch, that will be extremely wasteful. Instead we want to synchronize the gradients at the last `micro step` where micro step is `accu_step - 1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DDPGradAccuTrainCB(GradAccuTrainCB):\n",
    "\n",
    "    def backward(self, learn):\n",
    "        if ddp_enabled:\n",
    "            learn.model.require_backward_grad_sync = (\n",
    "                learn._micro_step_count % self.accu_steps == (self.accu_steps - 1)\n",
    "            )\n",
    "        super().backward(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite tricky to start DDP from notebook, so we will use the `train_gpt2.py` script to train the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
